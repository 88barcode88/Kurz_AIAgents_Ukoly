# Projekt: Reinforcement Learning - Q-learning pro FrozenLake

Tento projekt je implementacÃ­ algoritmu Q-learning pro Å™eÅ¡enÃ­ prostÅ™edÃ­ "FrozenLake-v1" z knihovny `gymnasium`. Byl vypracovÃ¡n v rÃ¡mci kurzu AI Agenti.

## ğŸ“‹ Popis

Agent se pomocÃ­ Q-tabulky uÄÃ­ optimÃ¡lnÃ­ politiku (cestu) v mÅ™Ã­Å¾kovÃ©m svÄ›tÄ› 4x4. CÃ­lem je dostat se z poÄÃ¡teÄnÃ­ho stavu (S) do cÃ­lovÃ©ho stavu (G) bez pÃ¡du do dÃ­ry (H).

### Mapa prostÅ™edÃ­:

SFFF
FHFH
FFFH
HFFG

- S: Start (poÄÃ¡teÄnÃ­ pozice)
- F: Frozen (zmrzlÃ¡ plocha - bezpeÄnÃ¡)
- H: Hole (dÃ­ra - konec hry)
- G: Goal (cÃ­l - vÃ­tÄ›zstvÃ­)

## ğŸ¯ VÃ½sledky trÃ©ninku

Agent se ÃºspÄ›Å¡nÄ› nauÄil Å™eÅ¡it Ãºkol s vysokou ÃºspÄ›Å¡nostÃ­ po 20 000 trÃ©novacÃ­ch epizodÃ¡ch. Skript automaticky uklÃ¡dÃ¡ nÃ¡sledujÃ­cÃ­ vÃ½stupy do sloÅ¾ky `vysledky/`:

- **Graf uÄenÃ­** - vizualizace prÅ¯bÄ›hu trÃ©ninku a histogram odmÄ›n
- **Q-tabulka** - nauÄenÃ© hodnoty ve formÃ¡tu `.npy`
- **Statistiky** - detailnÃ­ vÃ½sledky trÃ©ninku v textovÃ©m souboru

![Graf uÄenÃ­](./vysledky/graf_uceni_20250802_151527.png)

## ğŸš€ Jak spustit projekt

### 1. Naklonujte repozitÃ¡Å™:
```bash
git clone https://github.com/88barcode88/Kurz_AIAgents_Ukoly.git
cd Kurz_AIAgents_Ukoly/Lekce_10

2. VytvoÅ™te a aktivujte virtuÃ¡lnÃ­ prostÅ™edÃ­:

Windows:

# VytvoÅ™enÃ­
python -m venv venv

# Aktivace
.\venv\Scripts\activate

Linux/Mac:

# VytvoÅ™enÃ­
python3 -m venv venv

# Aktivace
source venv/bin/activate

3. Nainstalujte potÅ™ebnÃ© knihovny:

pip install -r requirements.txt

4. SpusÅ¥te hlavnÃ­ skript:

python trenovani.py

Po spuÅ¡tÄ›nÃ­ se zobrazÃ­:

PrÅ¯bÄ›Å¾nÃ© informace o trÃ©ninku
Graf s vÃ½sledky uÄenÃ­
VizuÃ¡lnÃ­ demonstrace nauÄenÃ©ho agenta (5 epizod)
VÅ¡echny vÃ½sledky se automaticky uloÅ¾Ã­ do sloÅ¾ky vysledky/

ğŸ“¦ Struktura projektu

Lekce_10/
â”‚
â”œâ”€â”€ trenovani.py          # HlavnÃ­ skript s implementacÃ­ Q-learning
â”œâ”€â”€ requirements.txt      # Seznam potÅ™ebnÃ½ch knihoven
â”œâ”€â”€ README.md            # Tento soubor
â”‚
â””â”€â”€ vysledky/            # SloÅ¾ka s vÃ½sledky (vytvoÅ™Ã­ se automaticky)
    â”œâ”€â”€ graf_uceni_*.png
    â”œâ”€â”€ q_tabulka_*.npy
    â””â”€â”€ statistiky_*.txt

ğŸ› ï¸ PouÅ¾itÃ© technologie

Python 3.8+
gymnasium - prostÅ™edÃ­ pro reinforcement learning
numpy - numerickÃ© vÃ½poÄty a Q-tabulka
matplotlib - vizualizace vÃ½sledkÅ¯

ğŸ“Š Hyperparametry

PoÄet epizod: 20 000
Learning rate (Î±): 0.1
Discount factor (Î³): 0.99
Epsilon-greedy strategie:
PoÄÃ¡teÄnÃ­ epsilon: 1.0
MinimÃ¡lnÃ­ epsilon: 0.01
Decay rate: 0.0001

ğŸ“ PoznÃ¡mky
ProstÅ™edÃ­ je nastaveno s parametrem is_slippery=False pro deterministickÃ© chovÃ¡nÃ­
Agent pouÅ¾Ã­vÃ¡ epsilon-greedy strategii pro vyvÃ¡Å¾enÃ­ explorace a exploitace
Q-hodnoty se aktualizujÃ­ pomocÃ­ Bellmanovy rovnice

ğŸ‘¤ Autor
VytvoÅ™eno v rÃ¡mci kurzu AI Agenti 
Miroslav CoufalÃ­k

ğŸ“„ Licence

Tento projekt je urÄen pro vzdÄ›lÃ¡vacÃ­ ÃºÄely.